{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "624085d0",
   "metadata": {},
   "source": [
    "### Export the data to Python (Jupyter Notebook + PySpark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37ef1f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in c:\\users\\koner\\anaconda3\\lib\\site-packages (5.28.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\koner\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: pytz in c:\\users\\koner\\anaconda3\\lib\\site-packages (from neo4j) (2023.3.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install neo4j pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65efffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "\n",
    "# Fill these with your Aura/Desktop credentials\n",
    "uri = \"bolt://localhost:7687\"  # e.g., bolt://localhost:7687 or Neo4j Aura bolt URL\n",
    "username = \"neo4j\"\n",
    "password = \"12345678\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d6cbbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koner\\AppData\\Local\\Temp\\ipykernel_18324\\4013869394.py:10: DeprecationWarning: read_transaction has been renamed to execute_read\n",
      "  edges = session.read_transaction(fetch_friend_edges)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0  61  62\n",
       "1  61  63\n",
       "2  61  64\n",
       "3  61  65\n",
       "4  61  66"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_friend_edges(tx):\n",
    "    query = \"\"\"\n",
    "    MATCH (u1:User)-[:FRIEND]-(u2:User)\n",
    "    WHERE u1.id < u2.id\n",
    "    RETURN u1.id AS user1, u2.id AS user2\n",
    "    \"\"\"\n",
    "    return list(tx.run(query))\n",
    "\n",
    "with driver.session() as session:\n",
    "    edges = session.read_transaction(fetch_friend_edges)\n",
    "\n",
    "df = pd.DataFrame(edges)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1266cc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koner\\AppData\\Local\\Temp\\ipykernel_18324\\2048463230.py:9: DeprecationWarning: read_transaction has been renamed to execute_read\n",
      "  users = session.read_transaction(fetch_users)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>[travel, tech]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>[travel, sports]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>Austin</td>\n",
       "      <td>[reading, travel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>SF</td>\n",
       "      <td>[tech, music]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>LA</td>\n",
       "      <td>[tech, cooking]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1        2                  3\n",
       "0  1  26  Seattle     [travel, tech]\n",
       "1  2  26  Chicago   [travel, sports]\n",
       "2  3  47   Austin  [reading, travel]\n",
       "3  4  39       SF      [tech, music]\n",
       "4  5  28       LA    [tech, cooking]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_users(tx):\n",
    "    query = \"\"\"\n",
    "    MATCH (u:User)\n",
    "    RETURN u.id AS id, u.age AS age, u.location AS location, u.interests AS interests\n",
    "    \"\"\"\n",
    "    return list(tx.run(query))\n",
    "\n",
    "with driver.session() as session:\n",
    "    users = session.read_transaction(fetch_users)\n",
    "\n",
    "users_df = pd.DataFrame(users)\n",
    "users_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b914c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"friend_edges.csv\", index=False)\n",
    "users_df.to_csv(\"user_attributes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df377c1",
   "metadata": {},
   "source": [
    "### Prepare Data for Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b872ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(edges, columns=[\"user1\", \"user2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1975ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user1</th>\n",
       "      <th>user2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user1 user2\n",
       "0    61    62\n",
       "1    61    63\n",
       "2    61    64\n",
       "3    61    65\n",
       "4    61    66"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1320bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = list(set(df['user1'].tolist() + df['user2'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24d3ad7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['170',\n",
       " '143',\n",
       " '157',\n",
       " '140',\n",
       " '113',\n",
       " '128',\n",
       " '73',\n",
       " '184',\n",
       " '133',\n",
       " '84',\n",
       " '106',\n",
       " '155',\n",
       " '98',\n",
       " '144',\n",
       " '148',\n",
       " '187',\n",
       " '96',\n",
       " '122',\n",
       " '153',\n",
       " '111',\n",
       " '162',\n",
       " '190',\n",
       " '152',\n",
       " '138',\n",
       " '139',\n",
       " '77',\n",
       " '199',\n",
       " '102',\n",
       " '192',\n",
       " '64',\n",
       " '134',\n",
       " '62',\n",
       " '172',\n",
       " '97',\n",
       " '179',\n",
       " '191',\n",
       " '186',\n",
       " '69',\n",
       " '104',\n",
       " '101',\n",
       " '141',\n",
       " '92',\n",
       " '70',\n",
       " '175',\n",
       " '173',\n",
       " '91',\n",
       " '68',\n",
       " '163',\n",
       " '105',\n",
       " '120',\n",
       " '99',\n",
       " '156',\n",
       " '178',\n",
       " '174',\n",
       " '71',\n",
       " '61',\n",
       " '116',\n",
       " '150',\n",
       " '154',\n",
       " '127',\n",
       " '130',\n",
       " '145',\n",
       " '135',\n",
       " '160',\n",
       " '167',\n",
       " '79',\n",
       " '147',\n",
       " '86',\n",
       " '136',\n",
       " '66',\n",
       " '95',\n",
       " '196',\n",
       " '193',\n",
       " '107',\n",
       " '158',\n",
       " '195',\n",
       " '115',\n",
       " '89',\n",
       " '100',\n",
       " '78',\n",
       " '74',\n",
       " '149',\n",
       " '177',\n",
       " '142',\n",
       " '126',\n",
       " '185',\n",
       " '159',\n",
       " '88',\n",
       " '188',\n",
       " '181',\n",
       " '72',\n",
       " '165',\n",
       " '112',\n",
       " '117',\n",
       " '151',\n",
       " '198',\n",
       " '63',\n",
       " '168',\n",
       " '90',\n",
       " '80',\n",
       " '137',\n",
       " '83',\n",
       " '87',\n",
       " '108',\n",
       " '119',\n",
       " '200',\n",
       " '75',\n",
       " '109',\n",
       " '103',\n",
       " '93',\n",
       " '183',\n",
       " '123',\n",
       " '182',\n",
       " '132',\n",
       " '67',\n",
       " '85',\n",
       " '110',\n",
       " '176',\n",
       " '189',\n",
       " '169',\n",
       " '146',\n",
       " '114',\n",
       " '125',\n",
       " '65',\n",
       " '121',\n",
       " '166',\n",
       " '76',\n",
       " '124',\n",
       " '129',\n",
       " '164',\n",
       " '94',\n",
       " '131',\n",
       " '82',\n",
       " '118',\n",
       " '161',\n",
       " '180',\n",
       " '197',\n",
       " '81',\n",
       " '194',\n",
       " '171']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99683fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Set of existing friend pairs for lookup\n",
    "positive_set = set(tuple(sorted([a, b])) for a, b in zip(df['user1'], df['user2']))\n",
    "\n",
    "# Generate negative pairs\n",
    "neg_samples = set()\n",
    "while len(neg_samples) < len(positive_set):\n",
    "    u1, u2 = random.sample(users, 2)\n",
    "    pair = tuple(sorted([u1, u2]))\n",
    "    if pair not in positive_set:\n",
    "        neg_samples.add(pair)\n",
    "\n",
    "# Create DataFrame for negative samples\n",
    "neg_df = pd.DataFrame(list(neg_samples), columns=['user1', 'user2'])\n",
    "neg_df['label'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4a87f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user1</th>\n",
       "      <th>user2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user1 user2  label\n",
       "0   158    61      1\n",
       "1   199    94      1\n",
       "2   187   188      1\n",
       "3   140   177      1\n",
       "4   140   152      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = 1\n",
    "all_df = pd.concat([df, neg_df], ignore_index=True)\n",
    "all_df = all_df.sample(frac=1).reset_index(drop=True)  # shuffle the data\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14827ccd",
   "metadata": {},
   "source": [
    "### Train PySpark ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ba42ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"python\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed864f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84948b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\koner\\anaconda3\\lib\\site-packages (3.5.5)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "648a3ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"FriendLinkPrediction\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df373035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user1: string (nullable = true)\n",
      " |-- user2: string (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      "\n",
      "+-----+-----+-----+\n",
      "|user1|user2|label|\n",
      "+-----+-----+-----+\n",
      "|  158|   61|    1|\n",
      "|  199|   94|    1|\n",
      "|  187|  188|    1|\n",
      "|  140|  177|    1|\n",
      "|  140|  152|    1|\n",
      "+-----+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark.createDataFrame(all_df)\n",
    "spark_df.printSchema()\n",
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55d44a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Convert user1 and user2 to numeric indices\n",
    "indexer1 = StringIndexer(inputCol=\"user1\", outputCol=\"user1_index\")\n",
    "indexer2 = StringIndexer(inputCol=\"user2\", outputCol=\"user2_index\")\n",
    "\n",
    "# Assemble into a single feature vector\n",
    "assembler = VectorAssembler(inputCols=[\"user1_index\", \"user2_index\"], outputCol=\"features\")\n",
    "\n",
    "# Logistic Regression model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=[indexer1, indexer2, assembler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdfe8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d359754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+----------+--------------------+\n",
      "|user1|user2|label|prediction|         probability|\n",
      "+-----+-----+-----+----------+--------------------+\n",
      "|  158|   61|    1|       1.0|[0.28387352059302...|\n",
      "|  199|   94|    1|       0.0|[0.65870439753559...|\n",
      "|  187|  188|    1|       1.0|[0.44532801374742...|\n",
      "|  140|  177|    1|       0.0|[0.69615190190412...|\n",
      "|  140|  152|    1|       1.0|[0.39369394129160...|\n",
      "|  161|  171|    1|       0.0|[0.56258892155990...|\n",
      "|  126|   71|    0|       0.0|[0.50988054587811...|\n",
      "|  146|   98|    0|       1.0|[0.42117700766169...|\n",
      "|  134|   73|    0|       1.0|[0.36884661727711...|\n",
      "|  140|  149|    1|       0.0|[0.78233808080798...|\n",
      "+-----+-----+-----+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(spark_df)\n",
    "predictions.select(\"user1\", \"user2\", \"label\", \"prediction\", \"probability\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9691430",
   "metadata": {},
   "source": [
    "### Export results and Streamlit Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b874021",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pd = predictions.select(\"user1\", \"user2\", \"label\", \"prediction\", \"probability\").toPandas()\n",
    "predictions_pd['prob_score'] = predictions_pd['probability'].apply(lambda x: x[1])  # probability of label=1\n",
    "predictions_pd.to_csv(\"friend_recommendations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "313184ed",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Obtaining dependency information for streamlit from https://files.pythonhosted.org/packages/13/e6/69fcbae3dd2fcb2f54283a7cbe03c8b944b79997f1b526984f91d4796a02/streamlit-1.45.1-py3-none-any.whl.metadata\n",
      "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Obtaining dependency information for altair<6,>=4.0 from https://files.pythonhosted.org/packages/aa/f3/0b6ced594e51cc95d8c1fc1640d3623770d01e4969d29c0bd09945fafefa/altair-5.5.0-py3-none-any.whl.metadata\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Obtaining dependency information for blinker<2,>=1.5.0 from https://files.pythonhosted.org/packages/10/cb/f2ad4230dc2eb1a74edf38f1a38b9b52277f75bef262d8908e60d957e13c/blinker-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from streamlit) (8.0.4)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from streamlit) (1.24.3)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from streamlit) (2.0.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from streamlit) (9.4.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from streamlit) (5.29.4)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from streamlit) (2.1.6)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Obtaining dependency information for gitpython!=3.1.19,<4,>=3.0.7 from https://files.pythonhosted.org/packages/1d/9a/4114a9057db2f1462d5c8f8390ab7383925fe1ac012eaa42402ad65c2963/GitPython-3.1.44-py3-none-any.whl.metadata\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Obtaining dependency information for pydeck<1,>=0.8.0b4 from https://files.pythonhosted.org/packages/ab/4c/b888e6cf58bd9db9c93f40d1c6be8283ff49d88919231afe93a6bcf61626/pydeck-0.9.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from streamlit) (6.3.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Obtaining dependency information for narwhals>=1.14.2 from https://files.pythonhosted.org/packages/c9/e0/ade8619846645461c012498f02b93a659e50f07d9d9a6ffefdf5ea2c02a0/narwhals-1.41.0-py3-none-any.whl.metadata\n",
      "  Downloading narwhals-1.41.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\koner\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Obtaining dependency information for gitdb<5,>=4.0.1 from https://files.pythonhosted.org/packages/a0/61/5c78b91c3143ed5c14207f463aecfc8f9dbb5092fb2869baf37c273b2705/gitdb-4.0.12-py3-none-any.whl.metadata\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2023.11.17)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/04/be/d09147ad1ec7934636ad912901c5fd7667e1c858e19d355237db0d0cd5e4/smmap-5.0.2-py3-none-any.whl.metadata\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\koner\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/9.9 MB 8.1 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/9.9 MB 10.2 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.7/9.9 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.6/9.9 MB 13.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.6/9.9 MB 15.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.9/9.9 MB 17.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.4/9.9 MB 19.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.0/9.9 MB 21.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.5/9.9 MB 22.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.9/9.9 MB 22.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.9/9.9 MB 20.3 MB/s eta 0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 731.2/731.2 kB 48.1 MB/s eta 0:00:00\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "   ---------------------------------------- 0.0/207.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 207.6/207.6 kB 13.2 MB/s eta 0:00:00\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.7/6.9 MB 53.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.0/6.9 MB 38.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.5/6.9 MB 41.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.5/6.9 MB 41.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 36.8 MB/s eta 0:00:00\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.8/62.8 kB ? eta 0:00:00\n",
      "Downloading narwhals-1.41.0-py3-none-any.whl (357 kB)\n",
      "   ---------------------------------------- 0.0/358.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 358.0/358.0 kB 23.2 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, narwhals, blinker, pydeck, gitdb, gitpython, altair, streamlit\n",
      "Successfully installed altair-5.5.0 blinker-1.9.0 gitdb-4.0.12 gitpython-3.1.44 narwhals-1.41.0 pydeck-0.9.1 smmap-5.0.2 streamlit-1.45.1\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31f12faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 11:48:51.825 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.945 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\koner\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-05-27 11:48:51.945 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.945 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.945 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.957 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.958 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.959 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.960 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.960 Session state does not function when running a script without `streamlit run`\n",
      "2025-05-27 11:48:51.961 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.961 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.966 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.966 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.995 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.996 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.997 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.997 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.997 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.998 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.998 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.998 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-05-27 11:48:51.999 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# Load prediction data\n",
    "df = pd.read_csv(\"friend_recommendations.csv\")\n",
    "\n",
    "# Sort by highest recommendation probability\n",
    "df = df.sort_values(by=\"prob_score\", ascending=False)\n",
    "\n",
    "st.title(\"🤝 Friend Recommendation System\")\n",
    "st.markdown(\"This app shows predicted friend recommendations based on user interactions.\")\n",
    "\n",
    "# User selection\n",
    "users = sorted(df['user1'].unique())\n",
    "selected_user = st.selectbox(\"Select a User:\", users)\n",
    "\n",
    "# Filter for top recommendations for this user\n",
    "recommendations = df[(df['user1'] == selected_user) & (df['prediction'] == 1)]\n",
    "recommendations = recommendations[['user2', 'prob_score']].sort_values(by='prob_score', ascending=False)\n",
    "\n",
    "st.subheader(f\"Top Recommended Friends for User {selected_user}\")\n",
    "st.dataframe(recommendations.head(10))\n",
    "\n",
    "# Optional: Show false negatives or interesting patterns\n",
    "st.markdown(\"----\")\n",
    "show_all = st.checkbox(\"Show all predictions?\")\n",
    "if show_all:\n",
    "    st.dataframe(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a76e1046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook SocialNetworkNeo4j.ipynb to script\n",
      "[NbConvertApp] Writing 4815 bytes to SocialNetworkNeo4j.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script SocialNetworkNeo4j.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6777a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
